# Ideas Brainstorm

While we still have not settled on an approach, we have considered the following ideas based on what we quickly surveyed:

- Studying explainability and interpretability of content moderation AI (specifically toxicity and online chat abuse AIs) and studying potential vectors of attack/defense
  - Someone made a reading list on Kaggle: <https://www.kaggle.com/c/jigsaw-toxic-severity-rating/discussion/286329/>
- Based on X-ray images of COVID-19 patients, explore interpretability of NN models designed to classify whether a patient has COVID-19 or not. Then survey existing image-based attacks and see if that can be applied to these models.
- Spectre side-channel attacks can cause malicious programs to steal secret from one's computer; there are existing protections proposed that uses machine learning to thwart the attacks. Unfortunately, most are using NN or deep learning and is susceptible to attacks. We can attempt to answer whether if existing attack methods can be used to circumvent these protections.
  - Example of a mechanism that attempts to stop side-channel attacks: [WHISPER](https://ieeexplore.ieee.org/abstract/document/9069285)


