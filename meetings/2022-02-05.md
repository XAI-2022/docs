

# Agenda

- Sign up for proposal discussion on Monday Feb 7.
- Milestone 1 -- proposal due on Tuesday Feb 15.
- Go around and talk about potential work -- given that we are a three-people team, we should
  try to apply whatever attacks against/defence for 2-3 models of differnet domains/applications

# Meeting Discussions

### ~~WHISPER~~

- It's a ensemble of ML to look at performance counters on the PC during an execution -- then a software ML model looks at those performance counters and detect if an attack is ongoing

### Content Moderation (Chosen)

- Existing methods are not too clever -- and uses simple sentiment analysis and classification -- we can use gradient-based attacks such as (Week 4 readings)
- To fit the scope of the project, we can survey literature for attacks against binary classifiers (such as malware detection, etc.) and apply them to toxic comment dataset.
- Then provide defenses against these type of attacks using peer-reviewed techniques, such as ensemble of multiple networks to cover non-accuracy related property of the application. (e.g. one network to predict whether a comment is toxic or not, and another network to predict the validity or other non-accuracy related property of the input data -- similar to what Esther did for her mushroom predictor)

